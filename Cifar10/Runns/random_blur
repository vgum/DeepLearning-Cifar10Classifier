Training samples: 50000
Validation samples: 10000
--
Training Step: 521  | total loss: 1.04796 | time: 13.481s
| Adam | epoch: 001 | loss: 1.04796 - acc: 0.6311 | val_loss: 1.06664 - val_acc: 0.6222 -- iter: 50000/50000
--
Training Step: 1042  | total loss: 0.82831 | time: 10.350s
| Adam | epoch: 002 | loss: 0.82831 - acc: 0.7109 | val_loss: 0.88008 - val_acc: 0.6933 -- iter: 50000/50000
--
Training Step: 1563  | total loss: 0.68174 | time: 10.249s
| Adam | epoch: 003 | loss: 0.68174 - acc: 0.7654 | val_loss: 0.79751 - val_acc: 0.7268 -- iter: 50000/50000
--
Training Step: 2084  | total loss: 0.64825 | time: 10.371s
| Adam | epoch: 004 | loss: 0.64825 - acc: 0.7857 | val_loss: 0.76129 - val_acc: 0.7396 -- iter: 50000/50000
--
Training Step: 2605  | total loss: 0.55145 | time: 10.495s
| Adam | epoch: 005 | loss: 0.55145 - acc: 0.8143 | val_loss: 0.77022 - val_acc: 0.7470 -- iter: 50000/50000
--
Training Step: 3126  | total loss: 0.47989 | time: 10.323s
| Adam | epoch: 006 | loss: 0.47989 - acc: 0.8425 | val_loss: 0.76320 - val_acc: 0.7495 -- iter: 50000/50000
--
Training Step: 3647  | total loss: 0.41962 | time: 10.386s
| Adam | epoch: 007 | loss: 0.41962 - acc: 0.8663 | val_loss: 0.77905 - val_acc: 0.7532 -- iter: 50000/50000
--
Training Step: 4168  | total loss: 0.38481 | time: 10.571s
| Adam | epoch: 008 | loss: 0.38481 - acc: 0.8842 | val_loss: 0.79774 - val_acc: 0.7499 -- iter: 50000/50000
--
Training Step: 4689  | total loss: 0.36028 | time: 10.244s
| Adam | epoch: 009 | loss: 0.36028 - acc: 0.8987 | val_loss: 0.86003 - val_acc: 0.7531 -- iter: 50000/50000
--
Training Step: 5210  | total loss: 0.35264 | time: 10.313s
| Adam | epoch: 010 | loss: 0.35264 - acc: 0.9118 | val_loss: 0.85169 - val_acc: 0.7591 -- iter: 50000/50000
--
Training Step: 5731  | total loss: 0.30080 | time: 10.392s
| Adam | epoch: 011 | loss: 0.30080 - acc: 0.9123 | val_loss: 0.92418 - val_acc: 0.7512 -- iter: 50000/50000
--
Training Step: 6252  | total loss: 0.36331 | time: 10.191s
| Adam | epoch: 012 | loss: 0.36331 - acc: 0.9259 | val_loss: 0.90431 - val_acc: 0.7544 -- iter: 50000/50000
--
Training Step: 6773  | total loss: 0.28854 | time: 10.199s
| Adam | epoch: 013 | loss: 0.28854 - acc: 0.9349 | val_loss: 0.99937 - val_acc: 0.7537 -- iter: 50000/50000
--
Training Step: 7294  | total loss: 0.38618 | time: 10.328s
| Adam | epoch: 014 | loss: 0.38618 - acc: 0.9286 | val_loss: 0.97370 - val_acc: 0.7559 -- iter: 50000/50000
--
Training Step: 7815  | total loss: 0.31056 | time: 10.280s
| Adam | epoch: 015 | loss: 0.31056 - acc: 0.9337 | val_loss: 0.99406 - val_acc: 0.7596 -- iter: 50000/50000
--
Training Step: 8336  | total loss: 0.39743 | time: 10.167s
| Adam | epoch: 016 | loss: 0.39743 - acc: 0.9244 | val_loss: 1.00549 - val_acc: 0.7550 -- iter: 50000/50000
--
Training Step: 8857  | total loss: 0.44968 | time: 10.195s
| Adam | epoch: 017 | loss: 0.44968 - acc: 0.9289 | val_loss: 1.07915 - val_acc: 0.7502 -- iter: 50000/50000
--
Training Step: 9378  | total loss: 0.49222 | time: 10.195s
| Adam | epoch: 018 | loss: 0.49222 - acc: 0.9331 | val_loss: 1.10473 - val_acc: 0.7540 -- iter: 50000/50000
--
Training Step: 9899  | total loss: 0.49419 | time: 10.250s
| Adam | epoch: 019 | loss: 0.49419 - acc: 0.9311 | val_loss: 1.08002 - val_acc: 0.7475 -- iter: 50000/50000
--
Training Step: 10420  | total loss: 0.42288 | time: 10.251s
| Adam | epoch: 020 | loss: 0.42288 - acc: 0.9341 | val_loss: 1.15907 - val_acc: 0.7598 -- iter: 50000/50000
--
Training Step: 10941  | total loss: 0.59751 | time: 10.230s
| Adam | epoch: 021 | loss: 0.59751 - acc: 0.9416 | val_loss: 1.13881 - val_acc: 0.7489 -- iter: 50000/50000
--
Training Step: 11462  | total loss: 0.52667 | time: 10.280s
| Adam | epoch: 022 | loss: 0.52667 - acc: 0.9283 | val_loss: 1.13835 - val_acc: 0.7464 -- iter: 50000/50000
--
Training Step: 11983  | total loss: 0.77847 | time: 10.211s
| Adam | epoch: 023 | loss: 0.77847 - acc: 0.9239 | val_loss: 1.19062 - val_acc: 0.7495 -- iter: 50000/50000
--
Training Step: 12504  | total loss: 0.72865 | time: 10.356s
| Adam | epoch: 024 | loss: 0.72865 - acc: 0.9237 | val_loss: 1.19920 - val_acc: 0.7509 -- iter: 50000/50000
--
Training Step: 13025  | total loss: 0.60902 | time: 10.279s
| Adam | epoch: 025 | loss: 0.60902 - acc: 0.9340 | val_loss: 1.14344 - val_acc: 0.7495 -- iter: 50000/50000
--
Training Step: 13546  | total loss: 0.72811 | time: 10.252s
| Adam | epoch: 026 | loss: 0.72811 - acc: 0.9343 | val_loss: 1.24773 - val_acc: 0.7571 -- iter: 50000/50000
--
Training Step: 14067  | total loss: 1.21136 | time: 10.256s
| Adam | epoch: 027 | loss: 1.21136 - acc: 0.9032 | val_loss: 1.25162 - val_acc: 0.7483 -- iter: 50000/50000
--
Training Step: 14588  | total loss: 0.79428 | time: 10.209s
| Adam | epoch: 028 | loss: 0.79428 - acc: 0.9242 | val_loss: 1.20467 - val_acc: 0.7469 -- iter: 50000/50000
--
Training Step: 15109  | total loss: 0.76162 | time: 10.205s
| Adam | epoch: 029 | loss: 0.76162 - acc: 0.9186 | val_loss: 1.26724 - val_acc: 0.7601 -- iter: 50000/50000
--
Training Step: 15630  | total loss: 1.45269 | time: 10.166s
| Adam | epoch: 030 | loss: 1.45269 - acc: 0.9004 | val_loss: 1.38218 - val_acc: 0.7511 -- iter: 50000/50000
--
Training Step: 16151  | total loss: 1.06215 | time: 10.239s
| Adam | epoch: 031 | loss: 1.06215 - acc: 0.9144 | val_loss: 1.37736 - val_acc: 0.7505 -- iter: 50000/50000
--
Training Step: 16672  | total loss: 1.67052 | time: 10.194s
| Adam | epoch: 032 | loss: 1.67052 - acc: 0.8812 | val_loss: 1.39693 - val_acc: 0.7478 -- iter: 50000/50000
--
Training Step: 17193  | total loss: 0.11611 | time: 10.218s
| Adam | epoch: 033 | loss: 0.11611 - acc: 0.9592 | val_loss: 1.40202 - val_acc: 0.7515 -- iter: 50000/50000
--
Training Step: 17714  | total loss: 0.13022 | time: 10.306s
| Adam | epoch: 034 | loss: 0.13022 - acc: 0.9574 | val_loss: 1.36549 - val_acc: 0.7579 -- iter: 50000/50000
--
Training Step: 18235  | total loss: 0.11021 | time: 10.155s
| Adam | epoch: 035 | loss: 0.11021 - acc: 0.9624 | val_loss: 1.45310 - val_acc: 0.7552 -- iter: 50000/50000
--
Training Step: 18756  | total loss: 0.10871 | time: 10.351s
| Adam | epoch: 036 | loss: 0.10871 - acc: 0.9659 | val_loss: 1.56418 - val_acc: 0.7503 -- iter: 50000/50000
--
Training Step: 19277  | total loss: 0.08921 | time: 10.409s
| Adam | epoch: 037 | loss: 0.08921 - acc: 0.9679 | val_loss: 1.59216 - val_acc: 0.7555 -- iter: 50000/50000
--
Training Step: 19798  | total loss: 0.07455 | time: 10.376s
| Adam | epoch: 038 | loss: 0.07455 - acc: 0.9752 | val_loss: 1.50720 - val_acc: 0.7550 -- iter: 50000/50000
--
Training Step: 20319  | total loss: 0.11453 | time: 10.230s
| Adam | epoch: 039 | loss: 0.11453 - acc: 0.9671 | val_loss: 1.49906 - val_acc: 0.7573 -- iter: 50000/50000
--
Training Step: 20840  | total loss: 0.09732 | time: 10.298s
| Adam | epoch: 040 | loss: 0.09732 - acc: 0.9619 | val_loss: 1.52103 - val_acc: 0.7556 -- iter: 50000/50000
--
Training Step: 21361  | total loss: 0.09467 | time: 10.402s
| Adam | epoch: 041 | loss: 0.09467 - acc: 0.9699 | val_loss: 1.60904 - val_acc: 0.7586 -- iter: 50000/50000
--
Training Step: 21882  | total loss: 0.11219 | time: 10.219s
| Adam | epoch: 042 | loss: 0.11219 - acc: 0.9660 | val_loss: 1.57442 - val_acc: 0.7529 -- iter: 50000/50000
--
Training Step: 22403  | total loss: 0.09978 | time: 10.257s
| Adam | epoch: 043 | loss: 0.09978 - acc: 0.9655 | val_loss: 1.60019 - val_acc: 0.7563 -- iter: 50000/50000
--
Training Step: 22924  | total loss: 0.10428 | time: 10.175s
| Adam | epoch: 044 | loss: 0.10428 - acc: 0.9670 | val_loss: 1.63490 - val_acc: 0.7475 -- iter: 50000/50000
--
Training Step: 23445  | total loss: 0.09377 | time: 10.316s
| Adam | epoch: 045 | loss: 0.09377 - acc: 0.9723 | val_loss: 1.55231 - val_acc: 0.7544 -- iter: 50000/50000
--
Training Step: 23966  | total loss: 0.07691 | time: 10.231s
| Adam | epoch: 046 | loss: 0.07691 - acc: 0.9770 | val_loss: 1.58637 - val_acc: 0.7551 -- iter: 50000/50000
--
Training Step: 24487  | total loss: 0.08977 | time: 10.175s
| Adam | epoch: 047 | loss: 0.08977 - acc: 0.9756 | val_loss: 1.65213 - val_acc: 0.7517 -- iter: 50000/50000
--
Training Step: 25008  | total loss: 0.08547 | time: 10.316s
| Adam | epoch: 048 | loss: 0.08547 - acc: 0.9655 | val_loss: 1.58027 - val_acc: 0.7577 -- iter: 50000/50000
--
Training Step: 25529  | total loss: 0.11172 | time: 10.322s
| Adam | epoch: 049 | loss: 0.11172 - acc: 0.9677 | val_loss: 1.66116 - val_acc: 0.7528 -- iter: 50000/50000
--
Training Step: 26050  | total loss: 0.08585 | time: 10.169s
| Adam | epoch: 050 | loss: 0.08585 - acc: 0.9730 | val_loss: 1.56570 - val_acc: 0.7503 -- iter: 50000/50000

