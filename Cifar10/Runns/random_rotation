Training samples: 50000
Validation samples: 10000
--
Training Step: 521  | total loss: 1.12182 | time: 10.731s
| Adam | epoch: 001 | loss: 1.12182 - acc: 0.5941 | val_loss: 1.09861 - val_acc: 0.6104 -- iter: 50000/50000
--
Training Step: 1042  | total loss: 0.88901 | time: 10.252s
| Adam | epoch: 002 | loss: 0.88901 - acc: 0.6897 | val_loss: 0.93200 - val_acc: 0.6703 -- iter: 50000/50000
--
Training Step: 1563  | total loss: 0.70655 | time: 10.318s
| Adam | epoch: 003 | loss: 0.70655 - acc: 0.7571 | val_loss: 0.80569 - val_acc: 0.7240 -- iter: 50000/50000
--
Training Step: 2084  | total loss: 0.62756 | time: 10.315s
| Adam | epoch: 004 | loss: 0.62756 - acc: 0.7900 | val_loss: 0.78631 - val_acc: 0.7324 -- iter: 50000/50000
--
Training Step: 2605  | total loss: 0.54333 | time: 10.266s
| Adam | epoch: 005 | loss: 0.54333 - acc: 0.8187 | val_loss: 0.76912 - val_acc: 0.7402 -- iter: 50000/50000
--
Training Step: 3126  | total loss: 0.50075 | time: 10.464s
| Adam | epoch: 006 | loss: 0.50075 - acc: 0.8400 | val_loss: 0.77054 - val_acc: 0.7502 -- iter: 50000/50000
--
Training Step: 3647  | total loss: 0.44248 | time: 10.223s
| Adam | epoch: 007 | loss: 0.44248 - acc: 0.8641 | val_loss: 0.76852 - val_acc: 0.7481 -- iter: 50000/50000
--
Training Step: 4168  | total loss: 0.38330 | time: 10.265s
| Adam | epoch: 008 | loss: 0.38330 - acc: 0.8839 | val_loss: 0.77407 - val_acc: 0.7585 -- iter: 50000/50000
--
Training Step: 4689  | total loss: 0.35252 | time: 10.215s
| Adam | epoch: 009 | loss: 0.35252 - acc: 0.9068 | val_loss: 0.86538 - val_acc: 0.7444 -- iter: 50000/50000
--
Training Step: 5210  | total loss: 0.34742 | time: 10.169s
| Adam | epoch: 010 | loss: 0.34742 - acc: 0.9061 | val_loss: 0.88829 - val_acc: 0.7474 -- iter: 50000/50000
--
Training Step: 5731  | total loss: 0.32318 | time: 10.241s
| Adam | epoch: 011 | loss: 0.32318 - acc: 0.9097 | val_loss: 0.88479 - val_acc: 0.7520 -- iter: 50000/50000
--
Training Step: 6252  | total loss: 0.33721 | time: 10.202s
| Adam | epoch: 012 | loss: 0.33721 - acc: 0.9163 | val_loss: 0.89914 - val_acc: 0.7512 -- iter: 50000/50000
--
Training Step: 6773  | total loss: 0.34526 | time: 10.271s
| Adam | epoch: 013 | loss: 0.34526 - acc: 0.9226 | val_loss: 0.99096 - val_acc: 0.7480 -- iter: 50000/50000
--
Training Step: 7294  | total loss: 0.32056 | time: 10.160s
| Adam | epoch: 014 | loss: 0.32056 - acc: 0.9356 | val_loss: 0.98442 - val_acc: 0.7518 -- iter: 50000/50000
--
Training Step: 7815  | total loss: 0.41873 | time: 10.277s
| Adam | epoch: 015 | loss: 0.41873 - acc: 0.9326 | val_loss: 0.99038 - val_acc: 0.7555 -- iter: 50000/50000
--
Training Step: 8336  | total loss: 0.30187 | time: 10.218s
| Adam | epoch: 016 | loss: 0.30187 - acc: 0.9453 | val_loss: 1.07278 - val_acc: 0.7471 -- iter: 50000/50000
--
Training Step: 8857  | total loss: 0.45866 | time: 10.237s
| Adam | epoch: 017 | loss: 0.45866 - acc: 0.9262 | val_loss: 1.05424 - val_acc: 0.7496 -- iter: 50000/50000
--
Training Step: 9378  | total loss: 0.35065 | time: 10.201s
| Adam | epoch: 018 | loss: 0.35065 - acc: 0.9370 | val_loss: 1.07768 - val_acc: 0.7507 -- iter: 50000/50000
--
Training Step: 9899  | total loss: 0.46738 | time: 10.205s
| Adam | epoch: 019 | loss: 0.46738 - acc: 0.9330 | val_loss: 1.10709 - val_acc: 0.7531 -- iter: 50000/50000
--
Training Step: 10420  | total loss: 0.50181 | time: 10.387s
| Adam | epoch: 020 | loss: 0.50181 - acc: 0.9342 | val_loss: 1.10259 - val_acc: 0.7524 -- iter: 50000/50000
--
Training Step: 10941  | total loss: 0.50380 | time: 10.199s
| Adam | epoch: 021 | loss: 0.50380 - acc: 0.9289 | val_loss: 1.12903 - val_acc: 0.7541 -- iter: 50000/50000
--
Training Step: 11462  | total loss: 0.44869 | time: 10.228s
| Adam | epoch: 022 | loss: 0.44869 - acc: 0.9328 | val_loss: 1.24116 - val_acc: 0.7578 -- iter: 50000/50000
--
Training Step: 11983  | total loss: 0.73937 | time: 10.161s
| Adam | epoch: 023 | loss: 0.73937 - acc: 0.9199 | val_loss: 1.14774 - val_acc: 0.7594 -- iter: 50000/50000
--
Training Step: 12504  | total loss: 0.84414 | time: 10.239s
| Adam | epoch: 024 | loss: 0.84414 - acc: 0.9158 | val_loss: 1.16412 - val_acc: 0.7504 -- iter: 50000/50000
--
Training Step: 13025  | total loss: 0.83663 | time: 10.223s
| Adam | epoch: 025 | loss: 0.83663 - acc: 0.9188 | val_loss: 1.21379 - val_acc: 0.7462 -- iter: 50000/50000
--
Training Step: 13546  | total loss: 0.69359 | time: 10.198s
| Adam | epoch: 026 | loss: 0.69359 - acc: 0.9339 | val_loss: 1.37671 - val_acc: 0.7396 -- iter: 50000/50000
--
Training Step: 14067  | total loss: 0.82351 | time: 10.227s
| Adam | epoch: 027 | loss: 0.82351 - acc: 0.9298 | val_loss: 1.27756 - val_acc: 0.7522 -- iter: 50000/50000
--
Training Step: 14588  | total loss: 0.99727 | time: 10.172s
| Adam | epoch: 028 | loss: 0.99727 - acc: 0.9112 | val_loss: 1.26937 - val_acc: 0.7489 -- iter: 50000/50000
--
Training Step: 15109  | total loss: 1.38952 | time: 10.223s
| Adam | epoch: 029 | loss: 1.38952 - acc: 0.8953 | val_loss: 1.39126 - val_acc: 0.7442 -- iter: 50000/50000
--
Training Step: 15630  | total loss: 0.92302 | time: 10.221s
| Adam | epoch: 030 | loss: 0.92302 - acc: 0.9207 | val_loss: 1.30935 - val_acc: 0.7499 -- iter: 50000/50000
--
Training Step: 16151  | total loss: 1.62641 | time: 10.398s
| Adam | epoch: 031 | loss: 1.62641 - acc: 0.8831 | val_loss: 1.35476 - val_acc: 0.7530 -- iter: 50000/50000
--
Training Step: 16672  | total loss: 1.31001 | time: 10.344s
| Adam | epoch: 032 | loss: 1.31001 - acc: 0.8981 | val_loss: 1.37895 - val_acc: 0.7504 -- iter: 50000/50000
--
Training Step: 17193  | total loss: 0.08544 | time: 10.370s
| Adam | epoch: 033 | loss: 0.08544 - acc: 0.9722 | val_loss: 1.41750 - val_acc: 0.7539 -- iter: 50000/50000
--
Training Step: 17714  | total loss: 0.08236 | time: 10.242s
| Adam | epoch: 034 | loss: 0.08236 - acc: 0.9711 | val_loss: 1.54222 - val_acc: 0.7546 -- iter: 50000/50000
--
Training Step: 18235  | total loss: 0.09730 | time: 10.224s
| Adam | epoch: 035 | loss: 0.09730 - acc: 0.9626 | val_loss: 1.46983 - val_acc: 0.7582 -- iter: 50000/50000
--
Training Step: 18756  | total loss: 0.13954 | time: 10.248s
| Adam | epoch: 036 | loss: 0.13954 - acc: 0.9542 | val_loss: 1.51747 - val_acc: 0.7539 -- iter: 50000/50000
--
Training Step: 19277  | total loss: 0.10865 | time: 10.704s
| Adam | epoch: 037 | loss: 0.10865 - acc: 0.9661 | val_loss: 1.53103 - val_acc: 0.7580 -- iter: 50000/50000
--
Training Step: 19798  | total loss: 0.09853 | time: 10.394s
| Adam | epoch: 038 | loss: 0.09853 - acc: 0.9672 | val_loss: 1.44575 - val_acc: 0.7552 -- iter: 50000/50000
--
Training Step: 20319  | total loss: 0.11887 | time: 10.324s
| Adam | epoch: 039 | loss: 0.11887 - acc: 0.9620 | val_loss: 1.53232 - val_acc: 0.7502 -- iter: 50000/50000
--
Training Step: 20840  | total loss: 0.08605 | time: 10.256s
| Adam | epoch: 040 | loss: 0.08605 - acc: 0.9760 | val_loss: 1.52619 - val_acc: 0.7518 -- iter: 50000/50000
--
Training Step: 21361  | total loss: 0.09724 | time: 10.273s
| Adam | epoch: 041 | loss: 0.09724 - acc: 0.9733 | val_loss: 1.54049 - val_acc: 0.7478 -- iter: 50000/50000
--
Training Step: 21882  | total loss: 0.11617 | time: 10.350s
| Adam | epoch: 042 | loss: 0.11617 - acc: 0.9636 | val_loss: 1.52703 - val_acc: 0.7517 -- iter: 50000/50000
--
Training Step: 22403  | total loss: 0.11572 | time: 10.427s
| Adam | epoch: 043 | loss: 0.11572 - acc: 0.9617 | val_loss: 1.56802 - val_acc: 0.7490 -- iter: 50000/50000
--
Training Step: 22924  | total loss: 0.10932 | time: 10.430s
| Adam | epoch: 044 | loss: 0.10932 - acc: 0.9643 | val_loss: 1.61965 - val_acc: 0.7514 -- iter: 50000/50000
--
Training Step: 23445  | total loss: 0.08310 | time: 10.257s
| Adam | epoch: 045 | loss: 0.08310 - acc: 0.9738 | val_loss: 1.61969 - val_acc: 0.7562 -- iter: 50000/50000
--
Training Step: 23966  | total loss: 0.08054 | time: 10.361s
| Adam | epoch: 046 | loss: 0.08054 - acc: 0.9745 | val_loss: 1.63182 - val_acc: 0.7514 -- iter: 50000/50000
--
Training Step: 24487  | total loss: 0.08325 | time: 10.311s
| Adam | epoch: 047 | loss: 0.08325 - acc: 0.9747 | val_loss: 1.67433 - val_acc: 0.7464 -- iter: 50000/50000
--
Training Step: 25008  | total loss: 0.08826 | time: 10.272s
| Adam | epoch: 048 | loss: 0.08826 - acc: 0.9694 | val_loss: 1.67485 - val_acc: 0.7526 -- iter: 50000/50000
--
Training Step: 25529  | total loss: 0.07555 | time: 10.131s
| Adam | epoch: 049 | loss: 0.07555 - acc: 0.9757 | val_loss: 1.66695 - val_acc: 0.7519 -- iter: 50000/50000
--
Training Step: 26050  | total loss: 0.08991 | time: 10.142s
| Adam | epoch: 050 | loss: 0.08991 - acc: 0.9712 | val_loss: 1.54431 - val_acc: 0.7529 -- iter: 50000/50000
